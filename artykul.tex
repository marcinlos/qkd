\documentclass[10pt]{article}


\usepackage{csagh}

\usepackage[utf8]{inputenc}
\usepackage{lmodern} 
\usepackage[T1]{fontenc}
\usepackage{microtype}

\usepackage{url}

\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{braket}
\usepackage[ruled]{algorithm2e}

\usepackage{polski}
\usepackage[polish]{babel}


\newtheorem{theorem}{Theorem}

\begin{document}
\begin{opening}

\title{Quantum Key Distribution}
\author[AGH University of Science and Technology, anna.jagodzinska91@gmail.com]{Anna Jagodzińska}

\begin{abstract}
  (Abstrakt)
\end{abstract}

\keywords{key distribution, quantum cryptography}

\end{opening}

\section{Problem dystrybucji klucza}

Problem dystrybucji klucza w kryptografii to protokół umożliwiający dwóm komunikującym się bytom
uzgodnienie wspólnego tajnego klucza, nie znanego przez nikogo z zewnątrz. Od początku historii
kryptografii dystrybucja klucza stanowiła jeden z najbardziej kłopotliwych praktycznych jej aspektów.
Niezależnie od siły szyfru, bezpieczeństwo klucza jest niezbędne do bezpieczeństwa komunikacji i danych
przez niego chronionych. Przed wynalezieniem kryptografii asymetrycznej do bezpiecznej komunikacji 
potrzebny był obydwu stronom tajny, uzgodniony wcześniej klucz, który musiał w jakiś sposób fizycznie 
zostać przekazany przed rozpoczęciem komunikacji. W czasie drugiej wojny światowej japońska marynarka
przykładowo używała tzw. książek kodowych. Rozwiązanie to miało poważne wady -- ryzyko przechwycenia
ich przez nieprzyjaciela było dość duże, a co za tym idzie, kody musiały być często zmieniane, co 
wymagało ponownego ich drukowania i rozprowadzenia. Szczególnie w trudnych warunkach wojennych,
bezpieczna dystrybucja klucza, od której niejednokrotnie zależało powodzenie operacji militarnych,
a więc życie żołnieży, była zadaniem niełatwym. 

Dzisiaj, jakkolwiek dysponujemy kryptografią asymetryczną, szyfry symetryczne wciąż są szeroko 
stosowane, m. in. ze względu na znacznie większą wydajność \cite{IntelAES, IntelSSL} -- szyfry 
symetryczne zazwyczaj wykorzystują proste operacje bitowe, podczas gdy np. RSA potrzebuje arytmetyki
modularnej \footnotemark. Stąd, kryptografia asymetryczna często wykorzystywana jest do zainicjowania
komunikacji i wygenerowania klucza (np. protokół Diffiego-Hellmana), który następnie jest używany do
szyfrowania symetrycznego. Jednym z najszerzej znanych przykładów takiego schematu jest protokół
SSL, który używa protokołu Diffiego-Hellmana w początkowej fazie komunikacji, by ustalić klucz,
który używany będzie do zapewnienia bezpieczeństwa pozostałej jego części. Po zakończonym sukcesem
procesie uwierzytelniania, do komunikacji używany jest szyfr symetryczny (najczęściej AES).

\footnotetext{
Cytowane materiały Intela pokazują niecałe 4000 operacji na sekundę przy 1024-bitowym kluczu RSA,
oraz czasy rzędu kilku cykli na bajt dla szyfru symetrycznego AES -- różnica to co najmniej 3 
rzędy wielkości.
}


\section{Szyfrowanie one-time pad}

Jednym z najbardziej atrakcyjnych potencjalnych przypadków użycia dla ewentualnego w pełni bezpiecznego
protokołu dystrybucji klucza jest z pewnością tzw. szyfr z kluczem jednorazowym (one-time pad). Jego
idea opiera się na wykorzystaniu klucza długości nie mniejszej niż sama szyfrowana wiadomość, i
wykonywaniu prostych operacji na fragmentach szyfrogramu i klucza. Przykład konkretnej implementacji:
tekstujawny i klucz przedstawiane są jako ciągi znaków z pewnego alfabetu alfabetu \(n\)-znakowego 
\(\mathcal{A}\), reprezentowanego przez liczby naturalne \(0,\ldots n-1\), tj. tekst jawny 
\(T=t_1\ldots t_m\), klucz \(K=k_1\ldots k_m\), zaś szyfrogram powstaje poprzez dodawanie odpowiadających
sobie znaków tekstu i klucza modulo \(n\), tj.
\[
S_i=\left(t_i\oplus k_i\right),\qquad a\oplus b \triangleq a+b \mod n
\]
Deszyfracja polega na odwróceniu tej operacji, tj. odejmowaniu kolejnych znaków klucza od znaków
szyfrogramu. Szyfr ten jest całkowicie bezpieczny w sensie teorii informacji -- szyfrogram nie zawiera
żadnej informacji o zaszyfrowanym tekście, poza maksymalną jego długością \cite{Shannon49}. Precyzyjnie
wyrazić to można przy użyciu pojęć teorii informacji -- entropii i entropii warunkowej. Wartości te 
stanowią miarę niepewności, informacji, które niesie ze sobą wystąpienie jakiegoś zdarzenia (w tym
przypadku, wystąpienie danego tekstu jawnego, lub szyfrogramu).
Dla dyskretnej zmiennej losowej \(X\), przyjmującej wartości \(x_1,\ldots,x_n\) z prawdopodobieństwami
\(p(x_1),\ldots,p(x_n)\), entropia zdefiniowana jest jako
\[
\mathcal{H}(X)=-\sum_{i=1}^n p(x_i)\log p(x_i)
\]
zaś dla drugiej zmiennej \(Y\), o wartościach \(y_1,\ldots,y_m\) entropia warunkowa, mierząca niepewność
co do wartości \(X\) gdy dana jest wartość \(Y\), wyraża się poprzez
\[
\mathcal{H}(X\mid Y)=-\sum_{i,j=1}^{n,m}p(x_i,y_j)\log \frac{p(x_i)}{p(x_i,y_j)}
\]
(dla \(p(x_i,y_j)=0\) w sumie przyjmujemy jako składnik \(0\)). Łatwo pokazać, że dla dowolnych \(X\),
\(Y\) jest \(\mathcal{H}(X\mid Y)\leq \mathcal{H}(X)\). Jeśli za \(X\) przyjmiemy zmienną losową
odpowiadającą rozkładowi tekstów jawnych, a za \(Y\) odpowiadających im szyfrogramów, intuicyjnie
\(\mathcal{H}(X\mid Y)\) mierzy jak wiele informacji o tekście jawnym daje znajomość szyfrogramu --
dla małych wartości daje dużo informacji (np. jeśli szyfrogramem byłby sam tekst jawny, z powyższego
wzoru otrzymamy entropię warunkową równą \(0\)), zaś dla dużych -- niewiele. Dowód bezpieczeństwa szyfru
one-time pad polega na pokazaniu, że dla w pełni losowego klucza, entropia warunkowa tekstu jawnego
względem szyfrogramu jest równa entropii samego tekstu jawnego, tj. 
\(\mathcal{H}(X\mid Y) = \mathcal{H}(X)\). Intuicyjnie, szyfrogram nie daje żadnej informacji o tekście
jawnym, ta ,,ukryta'' informacja jest w kluczu.

Powyższe rezultaty odnośnie szyfru z kluczem jednorazowym mają duże historyczne znaczenie teoretyczne.
Aby jednak szyfr był faktycznie bezpieczny, konieczne jest spełnienie szeregu dość restrykcyjnych
założeń.

\begin{itemize}
  \item Klucz musi być długości co najmniej takiej, jakiej jest tekst jawny
  \item Klucz musi być idealnie losowy
  \item Klucz może być wykorzystany tylko raz -- ponowne wykorzystanie klucza umożliwia kryptoanalizę
    opartą np. na niejednorodności rozkładu tekstu jawnego \footnotemark.
\end{itemize}

\footnotetext{
Przykładowo, w ekstremalnym przypadku gdy klucz jest jedną literą, każde wystąpienie danego znaku będzie
odpowiadać takiemu samemu znakowi. Pomijając oczywisty atak typu bruteforce, patrząc na szyfrogram
można z dużym prawdopodobieństwem stwierdzić, które jego znaki odpowiadają najczęściej występującym
w języku, w którym napisany został tekst jawny, porównując po prostu częstotliwość wystąpień.
}

Wymagania te sprawiają, że używanie szyfru z kluczem jednorazowym w praktyce jest dość kłopotliwe.
Szczególnie konieczność stosowania dużych, unikalnych kluczy, które obydwie strony komunikacji muszą
posiadać przed jej rozpoczęciem. Wymaga to wcześniejszego przygotowania -- gdyby istniał sposób
bezpiecznej transmisji klucza rozmiaru samej wiadomości bez możliwości przechwycenia go przez 
potencjalnych napastników, równie dobrze można by użyć takiego kanału do przekazania samej wiadomości.

Mimo tych problemów, szyfry z kluczem jednorazowym były stosunkowo popularne i często wykorzystywane
w sytuacjach, gdzie komunikacja nie była częsta, a niezbędny był bardzo wysoki stopień bezpieczeństwa,
np. przez sowieckich szpiegów w okresie zimnej wojny. Problemem była oczywiście dystrybucja kluczy
-- przechowywane były one na bardzo małych, łatwych do ukrycia kartkach papieru, często nasączonych
substancjami łatwopalnymi, by ułatwić natychmiastowe ich zniszczenie bez zostawienia śladów po użyciu.

Mimo to, trudno wyobrazić sobie używanie takiego systemu współcześnie, do szyfrowania komunikacji
,,na codzień''. Fizyczna dystrybucja kluczy zdaje się być zbyt niepraktycznym rozwiązaniem w sytuacji,
gdy komunikacja następuje pomiędzy wieloma parami uczestników, dynamicznie, i przesyłane są duże
ilości danych. Co więcej, zostało udowodnione \cite{Shannon49}, że każdy szyfr bezpieczy z punktu
widzenia teorii informacji ma podobnie kłopotliwe wymagania. W obliczu braku w pełni bezpiecznych,
szybkich i wygodnych protokołów dystrybucji klucza zmuszeni jesteśmy korzystać z szyfrów, których
bezpieczeństwo oparte jest jedynie o przypuszczalną \footnotemark trudność obliczeniową pewnych 
problemów algorytmicznych, jak faktoryzacja, czy obliczanie logarytmu dyskretnego.

\footnotetext{
Pomijając kwestię P vs NP, w przypadku której, jakkolwiek pozostaje niepewność, większość ekspertów
jest mocno przekonana, że równość nie zachodzi, w przypadku problemów najczęściej leżących u podstaw
algorytmów kryptograficznych -- faktoryzacji i obliczania logarytmu dyskretnego -- nie wiadomo nawet,
czy są NP-zupełne.
}

\section{Klasyczne metody generowania klucza}

W tej sekcji przyjrzymy się klasycznemu algorytmowi dystrybucji (tworzenia) klucza, opartemu
na trudności pewnych problemów obliczeniowych.

\subsection{Protokół Diffiego-Hellmana}

Przypuszczalnie najszerzej wykorzystywanym dziś protokołem uzgadniania klucza jest protokół 
Diffiego-Hellmana \cite{dh76}. Pozwala on dwóm komunikującym się stroną bezpiecznie stworzyć wspólny, 
tajny klucz tak, że ewentualny podsłuchiwacz, zdolny przechwycić całość komunikacji w obydwie strony,
nie jest w stanie w prosty sposób wyznaczyć jego wartości.

Załóżmy, że Alicja i Bob chcą stworzyć wspólny tajny klucz. Niech \(G=\langle g\rangle\) będzie grupą
cykliczną generowaną przez \(g\), znaną powszechnie -- Bob, Alicja, i ewnetualny podsłuchiwacz -- Ewa
-- znają \(G\) i \(g\). Protokół ma następujący przebieg:

\begin{enumerate}
  \item Alicja wybiera liczbę \(a\in\mathbb{N}\), oblicza \(g^a\) i wysyła Bobowi
  \item Bob wybiera liczbę \(b\in\mathbb{N}\), oblicza \(g^b\) i wysyła Alicji
  \item Alicja, znając \(a\) i \(g^b\), oblicza \(g^{ab}=\left(g^a\right)^b\)
  \item Bob, analogicznie, oblicza \(g^{ab}=\left(g^b\right)^a\)
\end{enumerate}

Tajny klucz to wartość \(g^{ab}\). Ewa jest w posiadaniu wartości \(g^a\) oraz \(g^b\), ale nie są
znane efektywne sposoby obliczenia \(g^{ab}\) na podstawie tych informacji. Problem jego wyznaczenia
znany jest w literaturze jako problem Diffiego-Hellmana\footnotemark. W praktyce jako grupę \(G\)
zazwyczaj wybiera się podgrupę multiplikatywną pewnego ciała Galois \(\mathbb{Z}/p\mathbb{Z}\), a
obliczenia sprowadzają się do znanej arytmetyki modularnej.

\subsection{Wersja dla więcej niż dwóch uczestników}

Zaprezentowany powyżej sposób postępowania można łatwo rozszerzyć na większą ilość uczestników,
obliczając w ogólności \(g^{a_1 \cdots a_n}\), gdzie \(a_1,\ldots,a_n\) to losowo wybrane przez nich
liczby. Protokół przebiega bardzo podobnie -- obliczane są i przekazywane odpowiednim osobom
wartości potęg \(g\) odpowiadających każdym podzbiorom właściwym zbioru 
\(\left\{a_1,\ldots,a_n\right\}\), t.j. \(g^{a_S}\), gdzie
\[
a_S = \prod_{i\in S}a_i,\ \ \ 
\emptyset\neq S\varsubsetneq \left\{1,\ldots,n\right\}
\]
(dla przypadku \(n=2\) były to \(\left\{a_1=a\right\}\) oraz
\(\left\{a_2=b\right\}\)). Podsłuchujący zna wszystkie te wartości, ale podobnie jak w wariancie
podstawowym, nie jest w stanie odtworzyć z nich prosto samego \(g^{a_1 \cdots a_n}\).

\section{Problemy}

Całe bezpieczeństwo protokołu opiera się na trudności problemu Diffiego-Hellmana. Rozwiązanie 
problemu obliczania logarytmu dyskretnego (DLP) wystarcza do obliczenia klucza, pozwala 
bowiem obliczyć \(a\) na podstawie znajomości \(g^a\), zatem problem Diffiego-Hellmana jest nie 
trudniejszy niż DLP, jednak redukcja w drugą stronę w ogólnym przypadku nie jest znana\footnotemark.
W przypadku problemu logarytmy dyskretnego niewiele wiadomo o faktycznej jego złożoności -- w
szczególności, nie wiadomo, czy problem jest NP-zupełny -- jednak jak dotąd nie jest znany algorytm
wielomianowy (przegląd istniejących algorytmów znaleźć można np. w \cite{Sutherland07}), więc uznać
można go w chwili obecnej za problem praktycznie trudny.

\footnotetext{
Ogólny przypadek zdaje się pozostawać problemem otwartym, natomiast istnieją wyniki częściowe.
Dla pewnej klasy liczb pierwszych zostało pokazane, że problem Diffiego-Hellmana jest nie prostszy
niż problem logarytmu dyskretnego \cite{Goldwasser90}. 
}

Warto również zaznaczyć, że jakkolwiek klasyczny wielomianowy algorytm dla problemu logarytmu 
dyskretnego nie jest znany, to istnieje efektywny algorytm kwantowy \cite{Shor97}, zatem ewentualny 
rozwój komputerów kwantowych wymusi tak czy inaczej zarzucenie użycia protokołu Diffiego-Hellmana
\footnotemark.

\footnotetext{
Na podobną przypadłość cierpi dużo znanych i powszechnie używanych obecnie algorytmów kryptografii
asymetrycznej, m. in. RSA -- efektywny kwantowy algorytm faktoryzacji opisany jest w tej samej
pracy \cite{Shor97}.
}

\section{Quantum Key Distribution}

\subsection{Początki kryptografii kwantowej}

Od samego początku swojego rozwoju jako dyscypliny czysto matematycznej, kryptografia nierozłącznie
związana była z teorią informacji i informatyką teoretyczną, w szczególności teorią obliczeń. Przy
użyciu jej narzędzi nie tylko analizować można było istniejące rozwiązania, ale także ściśle
dowodzić pewnych fundamentalnych ograniczeń przyjętego modelu. Brak możliwości uzyskania silniejszych
gwarancji bezpieczeństwa (często poparty matematycznymi dowodami, jak w przypadku wymagań dla 
szyfrowania doskonale bezpiecznego) skłaniał do tworzenia rozwiązań opartych o ,,trudne'' problemy
obliczeniowe. 

W tym okresie możliwe było już precyzyjne wyrażanie
takich idei. Pojęcie algorytmu, intuicyjnie rozumiane już od starożytności, w miarę rozwoju 
matematyki coraz głośniej domagało się ścisłej definicji. Dziesiąty problem Hilberta \cite{Gray01}
dotyczy algorytmu rozwiązywania wielomianowych równań Diofantycznych. O ile oczekiwana odpowiedź 
mogła zostać łatwo udzielona poprzez jego znalezienie i udowodnienie poprawności (nikt prawdopodobnie
nie miałby wątpliwości, czy zaprezentowany rezultat jest faktycznie ,,algorytmem''), to pokazanie,
że taki algorytm nie istnieje\footnote{Co też faktycznie ma miejsce -- dziesiąty problem Hilberta
rozwiązany został w 1970 r. poprzez udowodnienie, że żądany algorytm nie może istnieć 
\cite{Matiyasevich70}} bez ścisłej definicji algorytmu byłoby niemożliwe -- szczególnie,
że nikt w tamtym okresie nie spodziewał się takiego rozwiązania (Hilbert nie pyta nawet o istnienie
-- pyta o algorytm\footnotemark).
\footnotetext{
Hilbert głęboko wierzył, że sformalizowanie matematyki umożliwi prędzej czy później udzielenie
definitywnej odpowiedzi na wszelkie pytania. Sporą część kariery poświęcił na rozwój logiki i 
systemów formalnych. Jak na ironię, rezultaty burzące nadzieje na osiągnięcie w pełni tego, o czym
marzył, pojawiać zaczęły się kilka lat przed jego śmiercią (m. in. twierdzenia G\"{o}dla o 
niezupełności), szydząc niejako z jego słynnego epitafium -- \emph{,,Wir müssen wissen.
Wir werden wissen''}
}
Formalne definicje obliczenia, takie jak maszyna Turinga, czy rachunek lambda A. Churcha powstały 
niedługo potem. Są w swej naturze ,,skończone'' i ,,dyskretne'', mocno algebraiczne. Do dziś zdają
się stanowić adekwatny opis naszej intuicji odnośnie algorytmu. Rozwój fizyki i mechaniki kwantowej
pokazały jednak, że nasza intuicja o świecie, jakkolwiek przydatna i skuteczna w makroskali, nie
stanowi bynajmniej poprawnego jej opisu. Zaprzęgnięcie często nieintuicyjnych, niemal paradoksalnych,
potwierdzonych mimo to eksperymentalnie wniosków z teorii mechaniki kwantowej do tworzenia narzędzi
do obliczeń i komunikacji wymaga stworzenia i pracy w zupełnie nowym modelu kryptografii, dającym
nowe możliwości, i pozbawionym pewnych ograniczeń modelu klasycznego.
 
\subsection{Przewaga nad algorytmami klasycznymi}

Przy rozważaniu protokołów dystrybucji klucza zakładamy zazwyczaj, że przeciwnik -- Ewa -- ma możliwość
podsłuchania całej komunikacji pomiędzy jego uczestnikami. Jest to założenie uzasadnione -- gdyby nie
możliwość podsłuchania komunikacji, żadne zabezpieczenia nie byłyby wymagane. Trudno też z całą 
pewnością postawić ograniczenie górne na ilość podsłuchanych informacji, ani wykryć (przynajmniej
natychmiast) fakt podsłuchiwania, więc pełne bezpieczeństwo dać może jedynie protokół, który jest 
bezpieczny nawet w tak pesymistycznym przypadku. 

Podsłuchiwanie transmisji przez kanał kwantowy jednakowoż napotyka na istotną przeszkodę -- obserwacja
wymaga pomiaru, który zmienia przesyłany stan. W połączeniu z twierdzeniem o zakazie klonowania 
uniemożliwia to podsłuchiwaczowi działanie pozbawione wpływu na przesyłane dane. Okazuje się, że własność
ta pozwala konstruować protokoły, w których uczestnicy natychmiast dowiadują się nie tylko o fakcie
podsłuchiwania, ale także o tym, ile i jakie konkretnie informacje zostały przechwycone. Konkretne 
protokoły różnią się sposobem wykrywania podsłuchu i reakcją nań, ale możliwość ta stanowi główny 
czynnik odróżniający kwantową dystrybucję klucza od klasycznej, cechę unikalna dla niej i źródło jej 
siły.



\subsection{PAMIĘTAJ O SECURITY AMPLIFICATION}


\nocite{*}

\bibliographystyle{cs-agh}
\bibliography{bibliography}

\end{document}
